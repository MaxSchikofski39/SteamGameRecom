{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing_v2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TF-IDF matrix from preprocessed tag columns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "games_processed_all = games_processed.copy()\n",
    "tag_columns = games_processed_all.columns.difference([\"app_id\", \"title\", \"date_release\", \"rating\", \"user_reviews\", \"price_final\"])\n",
    "content_matrix = games_processed_all[tag_columns]\n",
    "\n",
    "# Apply TF-IDF transformation to encoded tags\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(content_matrix)\n",
    "\n",
    "# Create DataFrame for game-level TF-IDF vectors\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=games_processed_all[\"app_id\"], columns=content_matrix.columns)\n",
    "\n",
    "print(\"âœ… tfidf_df successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Build user profiles using training set and TF-IDF tag vectors\n",
    "\n",
    "user_profiles_tfidf = {}\n",
    "for user_id in df_train[\"user_id\"].unique():\n",
    "    app_ids = df_train[df_train[\"user_id\"] == user_id][\"app_id\"]\n",
    "    valid_ids = app_ids[app_ids.isin(tfidf_df.index)]\n",
    "    vectors = tfidf_df.loc[valid_ids]\n",
    "    if not vectors.empty:\n",
    "        user_profiles_tfidf[user_id] = vectors.mean(axis=0).values.reshape(1, -1)\n",
    "\n",
    "print(f\"âœ… Built TF-IDF profiles for {len(user_profiles_tfidf)} users.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… recommend_tfidf_contentwith fallback for cold start users\n",
    "\n",
    "def recommend_tfidf_content(user_id, top_n=10):\n",
    "    if user_id not in user_profiles_tfidf:\n",
    "        fallback = games_processed_all.sort_values(by=\"user_reviews\", ascending=False).head(top_n)\n",
    "        recs = fallback[[\"app_id\", \"title\"]].copy()\n",
    "        recs.insert(0, \"user_id\", user_id)\n",
    "        return recs\n",
    "\n",
    "    user_vector = user_profiles_tfidf[user_id]\n",
    "    similarities = cosine_similarity(user_vector, tfidf_df.values).flatten()\n",
    "\n",
    "    played = set(df_train[df_train[\"user_id\"] == user_id][\"app_id\"])\n",
    "    sorted_indices = similarities.argsort()[::-1]\n",
    "    recommended_ids = [tfidf_df.index[i] for i in sorted_indices if tfidf_df.index[i] not in played][:top_n]\n",
    "\n",
    "    recs = games_processed_all[games_processed_all[\"app_id\"].isin(recommended_ids)][[\"app_id\", \"title\"]].copy()\n",
    "    recs.insert(0, \"user_id\", user_id)\n",
    "    return recs\n",
    "\n",
    "print(\"âœ… Recommender supports fallback for cold users and can be evaluated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ” Demo: View a TF-IDF user profile and their top 5 content-based recommendations\n",
    "\n",
    "# Pick a sample user with a TF-IDF profile\n",
    "#sample_user_id = next(iter(user_profiles_tfidf.keys()))\n",
    "# ðŸ” Demo: Recommend games for any user (TF-IDF or fallback)\n",
    "\n",
    "sample_user_id = 20525  # Change this to test any user\n",
    "\n",
    "if sample_user_id in user_profiles_tfidf:\n",
    "    # âœ… TF-IDF path\n",
    "    user_vector = user_profiles_tfidf[sample_user_id]\n",
    "    similarities = cosine_similarity(user_vector, tfidf_df.values).flatten()\n",
    "\n",
    "    played = set(df_train[df_train[\"user_id\"] == sample_user_id][\"app_id\"])\n",
    "    sorted_indices = similarities.argsort()[::-1]\n",
    "    recommended_ids = [tfidf_df.index[i] for i in sorted_indices if tfidf_df.index[i] not in played][:5]\n",
    "\n",
    "    recommended_games = games_processed_all[games_processed_all[\"app_id\"].isin(recommended_ids)][[\"app_id\", \"title\"]].reset_index(drop=True)\n",
    "\n",
    "    # Show user's top tags\n",
    "    user_tag_scores = pd.Series(user_vector.flatten(), index=tfidf_df.columns).sort_values(ascending=False)\n",
    "    top_user_tags = user_tag_scores.head(10)\n",
    "\n",
    "    print(f\"ðŸ§‘â€ðŸ’» TF-IDF Recommendation for User ID: {sample_user_id}\")\n",
    "    print(\"\\nðŸ” Top Tags for this User:\")\n",
    "    display(top_user_tags)\n",
    "\n",
    "    print(\"\\nðŸŽ® Top 5 Game Recommendations:\")\n",
    "    display(recommended_games)\n",
    "\n",
    "else:\n",
    "    # ðŸ§Š Fallback for cold start user\n",
    "    recommendations = recommend_tfidf_content(sample_user_id, top_n=5)\n",
    "    print(f\"ðŸ§Š Fallback Recommendation for Cold Start User ID: {sample_user_id}\")\n",
    "    display(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Autoencoder-based Content-Based Recommender (Tag Embedding)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Step 1: Use tag matrix from already encoded tags\n",
    "tag_matrix = games_processed_all[tag_cols].values\n",
    "app_ids = games_processed_all[\"app_id\"].values\n",
    "\n",
    "# Step 2: Train a shallow autoencoder\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(50,), max_iter=2000, random_state=42)\n",
    "autoencoder.fit(tag_matrix, tag_matrix)\n",
    "\n",
    "# Step 3: Get latent representations (encoded tag vectors)\n",
    "encoded_vectors = autoencoder.predict(tag_matrix)\n",
    "latent_df = pd.DataFrame(encoded_vectors, index=app_ids)\n",
    "\n",
    "\n",
    "# Step 4: Build user profiles in latent space\n",
    "user_profiles_autoenc = {}\n",
    "for user_id in df_train[\"user_id\"].unique():\n",
    "    app_ids_user = df_train[df_train[\"user_id\"] == user_id][\"app_id\"]\n",
    "    valid_ids = app_ids_user[app_ids_user.isin(latent_df.index)]\n",
    "    user_vector = latent_df.loc[valid_ids].mean(axis=0)\n",
    "    if not user_vector.isna().any():\n",
    "        user_profiles_autoenc[user_id] = user_vector.values.reshape(1, -1)\n",
    "\n",
    "# Step 5: Recommendation function\n",
    "\n",
    "def recommend_autoencoder_content(user_id, top_n=10):\n",
    "    if user_id not in user_profiles_autoenc:\n",
    "        fallback = games_processed_all.sort_values(by=\"user_reviews\", ascending=False).head(top_n)\n",
    "        recs = fallback[[\"app_id\", \"title\"]].copy()\n",
    "        recs.insert(0, \"user_id\", user_id)\n",
    "        return recs\n",
    "\n",
    "    user_vector = user_profiles_autoenc[user_id]\n",
    "    similarities = cosine_similarity(user_vector, latent_df.values).flatten()\n",
    "\n",
    "    played = set(df_train[df_train[\"user_id\"] == user_id][\"app_id\"])\n",
    "    sorted_indices = similarities.argsort()[::-1]\n",
    "    recommended_ids = [latent_df.index[i] for i in sorted_indices if latent_df.index[i] not in played][:top_n]\n",
    "\n",
    "    recs = games_processed_all[games_processed_all[\"app_id\"].isin(recommended_ids)][[\"app_id\", \"title\"]].copy()\n",
    "    recs.insert(0, \"user_id\", user_id)\n",
    "    return recs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Demo: Recommend games for any user using Autoencoder (with fallback)\n",
    "\n",
    "sample_user_id = 20525  # Change this to test another user\n",
    "\n",
    "recommendations = recommend_autoencoder_content(sample_user_id, top_n=5)\n",
    "\n",
    "if sample_user_id in user_profiles_autoenc:\n",
    "    print(f\"\\U0001f9e0 Autoencoder-Based Recommendations for User ID: {sample_user_id}\")\n",
    "        \n",
    "    # Show top 10 latent dimensions for the user\n",
    "    user_vector = user_profiles_autoenc[sample_user_id]\n",
    "    user_latent_scores = pd.Series(user_vector.flatten(), index=[f\"latent_{i}\" for i in range(user_vector.shape[1])])\n",
    "    top_latent_features = user_latent_scores.sort_values(ascending=False).head(10)\n",
    "\n",
    "    print(\"\\nðŸ” Top Latent Dimensions for this User (Autoencoder):\")\n",
    "    display(top_latent_features)\n",
    "else:\n",
    "    print(f\"\\U0001f9ca Fallback for Cold Start User ID: {sample_user_id}\")\n",
    "\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_recommender(model_function, df_test, k=10):\n",
    "    \"\"\"\n",
    "    Evaluate a content-based recommender system using precision, recall, f1, accuracy, precision@k, ndcg@k.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_function: recommendation function taking user_id and top_n=k\n",
    "    - df_test: test set with user_id and app_id columns\n",
    "    - k: number of recommendations per user\n",
    "\n",
    "    Returns:\n",
    "    - metrics: dictionary with average scores\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    total_recommended = 0\n",
    "    total_relevant = 0\n",
    "\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    accuracy_scores = []\n",
    "    ndcg_scores = []\n",
    "\n",
    "    users_evaluated = 0\n",
    "\n",
    "    grouped_test = df_test.groupby(\"user_id\")\n",
    "    \n",
    "    for user_id, group in grouped_test:\n",
    "        true_items = set(group[\"app_id\"])\n",
    "        if not true_items:\n",
    "            continue\n",
    "\n",
    "        recs = model_function(user_id, top_n=k)\n",
    "        predicted_items = list(recs[\"app_id\"].dropna())\n",
    "        \n",
    "        if not predicted_items:\n",
    "            continue\n",
    "\n",
    "        y_true = [1 if app_id in true_items else 0 for app_id in predicted_items]\n",
    "        y_pred = [1] * len(predicted_items)  # recommender always predicts relevance\n",
    "\n",
    "        # Basic metrics\n",
    "        precision_scores.append(precision_score(y_true, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_true, y_pred, zero_division=0))\n",
    "        f1_scores.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        accuracy_scores.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        # Precision@k\n",
    "        hits = sum(y_true)\n",
    "        precision_at_k = hits / k\n",
    "        precision_scores.append(precision_at_k)\n",
    "\n",
    "        # NDCG@k\n",
    "        dcg = sum([int(relevant) / np.log2(idx + 2) for idx, relevant in enumerate(y_true)])\n",
    "        idcg = sum([1.0 / np.log2(i + 2) for i in range(min(len(true_items), k))])\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "        users_evaluated += 1\n",
    "\n",
    "    # Aggregate scores\n",
    "    metrics = {\n",
    "        \"Users Evaluated\": users_evaluated,\n",
    "        \"Avg Precision\": round(np.mean(precision_scores), 4),\n",
    "        \"Avg Recall\": round(np.mean(recall_scores), 4),\n",
    "        \"Avg F1\": round(np.mean(f1_scores), 4),\n",
    "        \"Avg Accuracy\": round(np.mean(accuracy_scores), 4),\n",
    "        \"Avg NDCG@k\": round(np.mean(ndcg_scores), 4)\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "results = evaluate_recommender(recommend_autoencoder_content, df_test_expanded, k=10)\n",
    "print(\"âœ… Evaluation Results (Autoencoder Recommender):\")\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
